{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AQUI COMEÇA A CONSTRUÇÂO DA CAMADA silver\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "# Funcao\n",
    "def create_table(table_name:str, has_input:bool, in_fld:str='/FileStore/tables/raw_file/delta'):\n",
    "    if has_input:\n",
    "        # Deleta a tabela caso exista\n",
    "        spark.sql(f\"\"\"\n",
    "        DROP TABLE IF EXISTS {table_name}\"\"\")\n",
    "        # cria uma nova tabela com os dados delta tratados anteriormente\n",
    "        spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name}\n",
    "        USING DELTA\n",
    "        LOCATION '{in_fld}'\n",
    "        \"\"\")\n",
    "        # Por termos uma serie de arquivos pequenos, 'e necessario\n",
    "        # rodar o optimize para reduzir arquivos pequenos em maiores\n",
    "        spark.sql(\"\"\"\n",
    "        OPTIMIZE default.bronze\n",
    "        \"\"\")\n",
    "    else:\n",
    "        # Deleta a tabela caso exista\n",
    "        spark.sql(f\"\"\"\n",
    "        DROP TABLE IF EXISTS {table_name};\n",
    "        \"\"\")\n",
    "        # cria uma nova tabela com os dados delta tratados anteriormente\n",
    "        spark.sql(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name}\n",
    "            (\n",
    "            dateTimeReference timestamp,\n",
    "            modifiedDate timestamp,\n",
    "            idRetailerSKU string,\n",
    "            seller string,\n",
    "            retailerProductCode string,\n",
    "            retailerAverageRating float,\n",
    "            retailerRatingCount int,\n",
    "            retailerPrice float, \n",
    "            manufacturerPrice float, \n",
    "            priceVariation float,\n",
    "            available boolean,\n",
    "            unavailable boolean,\n",
    "            notListed boolean,\n",
    "            titleFlag boolean,\n",
    "            titlePercentage float\n",
    "            );\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Carrega as informações da camada bronze e reestrutura para \n",
    "    # que cada elemento dentro de assortment seja uma coluna\n",
    "    df = spark.sql(\"select * from default.bronze\")\n",
    "    df_2 = df.withColumn('dateTimeReference', f.explode(f.col('assortment.dateTimeReference')))\\\n",
    "            .withColumn('modifiedDate', f.explode(f.col('assortment.modifiedDate')))\\\n",
    "            .withColumn('idRetailerSKU', f.explode(f.col('assortment.idRetailerSKU')))\\\n",
    "            .withColumn('seller', f.explode(f.col('assortment.seller')))\\\n",
    "            .withColumn('retailerProductCode', \\\n",
    "                        f.explode(f.col('assortment.retailerProductCode')))\\\n",
    "            .withColumn('retailerAverageRating', \\\n",
    "                        f.explode(f.col('assortment.retailerAverageRating')))\\\n",
    "            .withColumn('retailerRatingCount', \\\n",
    "                        f.explode(f.col('assortment.retailerRatingCount')))\\\n",
    "            .withColumn('retailerPrice', f.explode(f.col('assortment.retailerPrice')))\\\n",
    "            .withColumn('manufacturerPrice', f.explode(f.col('assortment.manufacturerPrice')))\\\n",
    "            .withColumn('priceVariation', f.explode(f.col('assortment.priceVariation')))\\\n",
    "            .withColumn('available', f.explode(f.col('assortment.available')))\\\n",
    "            .withColumn('unavailable', f.explode(f.col('assortment.unavailable')))\\\n",
    "            .withColumn('notListed', f.explode(f.col('assortment.notListed')))\\\n",
    "            .withColumn('titleFlag', f.explode(f.col('assortment.titleFlag')))\\\n",
    "            .withColumn('titlePercentage', f.explode(f.col('assortment.titlePercentage')))\\\n",
    "            .drop(f.col('assortment'))\n",
    "                        \n",
    "    # Essa parte é feita a tipagem das colunas\n",
    "    # TODO - Remover pois a tipagem já foi feita na camada bronze                    \n",
    "    df_2 = df_2.select(f.col('dateTimeReference')\n",
    "                     , f.col('modifiedDate')\n",
    "                     , f.col('idRetailerSKU')\n",
    "                     , f.col('seller')\n",
    "                     , f.col('retailerProductCode')\n",
    "                     , f.col('retailerAverageRating')\n",
    "                     , f.col('retailerRatingCount')\n",
    "                     , f.col('retailerPrice')\n",
    "                     , f.col('manufacturerPrice')\n",
    "                     , f.col('priceVariation')\n",
    "                     , f.col('available')\n",
    "                     , f.col('unavailable')\n",
    "                     , f.col('notListed')\n",
    "                     , f.col('titleFlag')\n",
    "                     , f.col('titlePercentage')\n",
    "                    )\n",
    "                        \n",
    "except Exception as e:\n",
    "    print(\"Nao foi possivel fazer a carga da tabela\" + '\\n' + f'Erro : {e}')\n",
    "else:\n",
    "    # Monitoramento dos dados\n",
    "    # Nessa parte há a validação das informações antes e depois da modificação     \n",
    "    # para monitorar se houve alguma perda de dado\n",
    "    if df.count() - df_2.count() == 0:\n",
    "        # se não houve, a gente cria a tabela atraves da função descrita\n",
    "        # e posteriormente salva os valores na camada silver\n",
    "        create_table(table_name='default.silver', has_input=False)\n",
    "        df_2.write.format(\"delta\").mode('overwrite').saveAsTable('default.silver')\n",
    "        print('Dados carregados com sucesso!')\n",
    "    # Caso haja inconsistencia dos dados, não salva a tabela e emite a divergência \n",
    "    # encontrada\n",
    "    else: \n",
    "        print(f'Incosistencia nos dados da carga. \\nTendo {df_2.count()} linhas na camada \\\n",
    "              silver e {df.count()} linhas na camada bronze')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
