{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessa tarefa, você deverá encontrar os 10 produtos com a maior variação de preço, \n",
    "# entre o valor encontrado no varejo online (Americanas) e o estipulado pelo fabricante\n",
    "df = spark.sql(\"\"\"\n",
    "select *\n",
    "from default.silver\n",
    "\"\"\")\n",
    "\n",
    "df_2 = df.withColumn('diff', f.when((f.col('retailerPrice') >= f.col('manufacturerPrice')*0.2)\\ \n",
    "                                    & (f.col('manufacturerPrice') >= f.col('retailerPrice')*0.2)\\\n",
    "                                    , (f.col('retailerPrice')) - (f.col('manufacturerPrice'))))\n",
    "\n",
    "df_2.groupby(f.col('retailerProductCode'))\\\n",
    "            .agg(f.max(f.col('diff')).alias('max_diff')).sort(f.desc(f.col('max_diff'))).show(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  e os 10 produtos que apresentam maior indisponibilidade.\n",
    "display(df.dropna(how='any', subset='titleFlag')\\\n",
    "            .groupby(f.col('retailerProductCode'))\\\n",
    "            .agg(f.sum(\n",
    "                    f.when((f.col('available')==False) & (f.col('titleFlag')==True), 1)\\\n",
    "                    .when((f.col('available')==True) & (f.col('titleFlag')==True), 0))\\\n",
    "                 .alias('unavailable_count'),\n",
    "                f.countDistinct(f.col('idRetailerSKU')))\\\n",
    "            .sort(f.desc('unavailable_count')).head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
